{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Forward-Forward Algorithm\n",
    "\n",
    "Original paper: https://www.cs.toronto.edu/~hinton/FFA13.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from dataset_utils import BreastCancerLoader, TrainingDatasetFF\n",
    "from models import FFMultiLayerPerceptron, MultiLayerPerceptron\n",
    "from tools import base_loss, generate_positive_negative_samples_overlay\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "pos_gen_fn = generate_positive_negative_samples_overlay # which function to use to generate pos neg examples\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_loader = BreastCancerLoader()\n",
    "bc_loader.download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = bc_loader.get_train_loader(train_batch_size)\n",
    "test_loader = bc_loader.get_test_loader(test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it takes 10s to prepare all training dataset\n",
    "train_loader_ff = torch.utils.data.DataLoader(TrainingDatasetFF(pos_gen_fn(X.to(device),\n",
    "                                                                           Y.to(device),\n",
    "                                                                           num_classes=2,\n",
    "                                                                           only_positive=False,\n",
    "                                                                           replace=False)\n",
    "                                                                for X, Y in train_loader),\n",
    "                                              batch_size=train_loader.batch_size, shuffle=True\n",
    "                                              )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Set some variables\n",
    "hidden_dimensions = [32, 5, 5] # first is input size\n",
    "activation = torch.nn.ReLU()\n",
    "layer_optim_learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam\n",
    "threshold = 2.0\n",
    "loss = base_loss \n",
    "method = \"MSE\"\n",
    "replace = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = FFMultiLayerPerceptron(hidden_dimensions, \n",
    "                                  activation,\n",
    "                                  optimizer,\n",
    "                                  layer_optim_learning_rate,\n",
    "                                  threshold,\n",
    "                                  loss,\n",
    "                                  method,\n",
    "                                  replace).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 195\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "\n",
    "for layer in mlp_model.layers:\n",
    "    # Count the parameters\n",
    "    num_params = count_parameters(layer)\n",
    "    total_params += num_params\n",
    "\n",
    "print(\"Number of parameters:\", total_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Set some variables\n",
    "n_epochs = 5\n",
    "\n",
    "# choose one of the following training procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x220860c00b0>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train all layers at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ed06f19e1c4838aca33bff0ff5e975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: 2.215082883834839, Layer 1: 2.22563672065734865\r"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for X_pos, Y_neg in train_loader_ff:\n",
    "        layer_losses = mlp_model.train_batch(X_pos, Y_neg, before=False)\n",
    "        print(\", \".join(map(lambda i, l: 'Layer {}: {}'.format(i, l),list(range(len(layer_losses))) ,layer_losses)), end='\\r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train one layer at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855b3cace96045c68e364c44a3ab1f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/60, Layer 0: 0.15289615094661713\n",
      "\n",
      "Epoch: 60/60, Layer 1: 0.75259268283843995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_model.train_batch_progressive(n_epochs, train_loader_ff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79ec05c924849fb8eeff051fa2b7764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.0440%\n",
      "Train error: 3.9560%\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for X_train, Y_train in tqdm(train_loader, total=len(train_loader)):\n",
    "    X_train = X_train.to(device)\n",
    "    Y_train = Y_train.to(device)\n",
    "\n",
    "    acc += (mlp_model.predict_accumulate_goodness(X_train,\n",
    "            pos_gen_fn, n_class=2).eq(Y_train).sum())\n",
    "\n",
    "print(f\"Accuracy: {acc/float(len(bc_loader.train_set)):.4%}\")\n",
    "print(f\"Train error: {1 - acc/float(len(bc_loader.train_set)):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2641a0c3916d41a3a9d3a54ad77405f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.2456%\n",
      "Test error: 1.7544%\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for X_test, Y_test in tqdm(test_loader, total=len(test_loader)):\n",
    "    X_test = X_test.to(device)\n",
    "    Y_test = Y_test.to(device)\n",
    "\n",
    "    acc += (mlp_model.predict_accumulate_goodness(X_test,\n",
    "            pos_gen_fn, n_class=2).eq(Y_test).sum())\n",
    "\n",
    "print(f\"Accuracy: {acc/float(len(bc_loader.test_set)):.4%}\")\n",
    "print(f\"Test error: {1 - acc/float(len(bc_loader.test_set)):.4%}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Set some variables\n",
    "n_epochs= 5\n",
    "hidden_dimensions = [30, 5, 5, 2]\n",
    "activation = torch.nn.ReLU()\n",
    "optimizer = torch.optim.Adam\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_backprop_model = MultiLayerPerceptron(hidden_dimensions, activation).to(device)\n",
    "optimizer = optimizer(mlp_backprop_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a783ae46594a418882c5f6fc7e15282e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6776123046875337\r"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for i, (X_train, Y_train) in enumerate(train_loader):\n",
    "        X_train = X_train.to(device)\n",
    "        Y_train = Y_train.type(torch.LongTensor).to(device)\n",
    "        \n",
    "        Y_pred = mlp_backprop_model(X_train)\n",
    "\n",
    "        loss = loss_fn(Y_pred, Y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Loss: {loss}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7381928a2c1d437a9889d874e6090f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.9670%\n",
      "Train error: 27.0330%\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for X_train, Y_train in tqdm(train_loader, total=len(train_loader)):\n",
    "    X_train = X_train.to(device)\n",
    "    Y_train = Y_train.to(device)\n",
    "\n",
    "    acc += (torch.softmax(mlp_backprop_model(X_train), 1).argmax(1).eq(Y_train).sum())\n",
    "\n",
    "print(f\"Accuracy: {acc/float(len(bc_loader.train_set)):.4%}\")\n",
    "print(f\"Train error: {1 - acc/float(len(bc_loader.train_set)):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d06500094eb430d815c63ff65abbccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.5614%\n",
      "Test error: 25.4386%\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for X_test, Y_test in tqdm(test_loader, total=len(test_loader)):\n",
    "    X_test = X_test.to(device)\n",
    "    Y_test = Y_test.to(device)\n",
    "\n",
    "    acc += (torch.softmax(mlp_backprop_model(X_test), 1).argmax(1).eq(Y_test).sum())\n",
    "\n",
    "print(f\"Accuracy: {acc/float(len(bc_loader.test_set)):.4%}\")\n",
    "print(f\"Test error: {1 - acc/float(len(bc_loader.test_set)):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return num_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 197\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "\n",
    "for layer in mlp_backprop_model.layers:\n",
    "    # Count the parameters\n",
    "    num_params = count_parameters(layer)\n",
    "    total_params += num_params\n",
    "\n",
    "print(\"Number of parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6905339ec9834455f3eeaf833f5d6a2573f0df69b633997954458b6d6617aa92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
